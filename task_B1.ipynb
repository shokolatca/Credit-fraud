{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElDqjXGkdlHy"
      },
      "source": [
        "### Задача B — антифрод через proxy-label / anomaly detection\n",
        "**Цель:** выявлять *подозрительные* кредиты/заявки, похожие на схему “early default”.\n",
        "\n",
        "**Вариант B1 (proxy-label):**\n",
        "- Формируем прокси-метку мошенничества:\n",
        "  - `fraud_proxy = 1`, если `loan_status=Charged Off` и `payment_ratio < τ` (например, τ=0.1),\n",
        "  - иначе `fraud_proxy = 0`.\n",
        "- Обучаем модель, которая по **заявочным** признакам (без leakage) предсказывает вероятность `fraud_proxy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import (\n",
        "    average_precision_score, roc_auc_score, \n",
        "    precision_recall_curve, f1_score, recall_score,\n",
        "    precision_score, confusion_matrix, classification_report,\n",
        "    PrecisionRecallDisplay, RocCurveDisplay\n",
        ")\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Для разреженных матриц\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Всего записей: 38576\n",
            "\n",
            "Распределение loan_status:\n",
            "loan_status\n",
            "Fully Paid     32145\n",
            "Charged Off     5333\n",
            "Current         1098\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('financial_loan.csv')\n",
        "\n",
        "print(f\"Всего записей: {len(df)}\")\n",
        "print(f\"\\nРаспределение loan_status:\")\n",
        "print(df['loan_status'].value_counts())\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "СТАТИСТИКА ПО МЕТКАМ:\n",
            "Charged Off: 5333 (14.2%)\n",
            "Fraud proxy (Charged Off + payment_ratio < 0.1): 206 (0.55%)\n",
            "Из Charged Off как fraud: 3.9%\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dfB1 = df[df[\"loan_status\"].isin([\"Fully Paid\", \"Charged Off\"])].copy()\n",
        "dfB1[\"payment_ratio\"] = dfB1[\"total_payment\"] / dfB1[\"loan_amount\"]\n",
        "dfB1[\"y\"] = ((dfB1[\"loan_status\"] == \"Charged Off\") & (dfB1[\"payment_ratio\"] < 0.1)).astype(int)\n",
        "fraud_count = dfB1[\"y\"].sum()\n",
        "total_charged_off = (dfB1['loan_status'] == 'Charged Off').sum()\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(\"СТАТИСТИКА ПО МЕТКАМ:\")\n",
        "print(f\"Charged Off: {total_charged_off} ({total_charged_off/len(dfB1)*100:.1f}%)\")\n",
        "print(f\"Fraud proxy (Charged Off + payment_ratio < 0.1): {fraud_count} ({fraud_count/len(dfB1)*100:.2f}%)\")\n",
        "print(f\"Из Charged Off как fraud: {fraud_count/total_charged_off*100:.1f}%\")\n",
        "print(f\"{'='*50}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "leak_cols_drop = [\n",
        "    \"total_payment\", \"last_payment_date\", \"next_payment_date\",\n",
        "    \"last_credit_pull_date\", \"id\", \"member_id\", \"application_type\",\n",
        "    \"loan_status\", \"payment_ratio\"  \n",
        "]\n",
        "dfB1 = dfB1.drop(columns=leak_cols_drop, errors='ignore')\n",
        "\n",
        "\n",
        "dfB1[\"issue_date\"] = pd.to_datetime(dfB1[\"issue_date\"], dayfirst=True)\n",
        "\n",
        "\n",
        "dates_to_drop = [\n",
        "    '2021-01-01', '2021-01-05', '2021-02-25', '2021-07-17',\n",
        "    '2021-11-19', '2021-09-02', '2021-07-22', '2021-12-02', '2021-12-12', '2021-02-02'\n",
        "]\n",
        "dates_to_drop = pd.to_datetime(dates_to_drop)\n",
        "dfB1 = dfB1[~dfB1[\"issue_date\"].isin(dates_to_drop)]\n",
        "\n",
        "\n",
        "dfB1[\"issue_month\"] = dfB1[\"issue_date\"].dt.month.astype(\"int16\")\n",
        "dfB1 = dfB1.drop(columns=[\"issue_date\"], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfB1[\"term_months\"] = dfB1[\"term\"].astype(str).str.extract(r\"(\\d+)\").astype(\"int16\")\n",
        "dfB1 = dfB1.drop(columns=[\"term\"], errors='ignore')\n",
        "\n",
        "\n",
        "p99_income = dfB1[\"annual_income\"].quantile(0.99)\n",
        "dfB1[\"annual_income_cap\"] = dfB1[\"annual_income\"].clip(upper=p99_income)\n",
        "dfB1[\"log_income\"] = np.log10(dfB1[\"annual_income_cap\"].replace(0, 1))\n",
        "dfB1 = dfB1.drop(columns=[\"annual_income\", \"annual_income_cap\"], errors='ignore')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "большие значения у среднего кридитного рейтинга"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "grade_map = {g: i+1 for i, g in enumerate(list(\"ABCDEFG\"))}\n",
        "dfB1[\"sub_grade_num\"] = dfB1[\"sub_grade\"].astype(str).apply(\n",
        "    lambda s: 5*(grade_map.get(s[0], np.nan)-1) + int(s[1]) if len(s) >= 2 and s[0] in grade_map else np.nan\n",
        ")\n",
        "\n",
        "CENTER = 13     \n",
        "MAX_SCORE = 20  \n",
        "\n",
        "dfB1[\"sub_grade_bell\"] = (\n",
        "    MAX_SCORE - (dfB1[\"sub_grade_num\"] - CENTER).abs()\n",
        ")\n",
        "\n",
        "\n",
        "dfB1[\"sub_grade_bell\"] = dfB1[\"sub_grade_bell\"].clip(lower=0)\n",
        "dfB1[\"sub_grade_num\"] = dfB1[\"sub_grade_bell\"].copy()\n",
        "dfB1 = dfB1.drop(columns=[\"grade\", \"sub_grade\", \"sub_grade_bell\"], errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def annuity_payment(L, annual_rate, n_months):\n",
        "    r = annual_rate / 12.0\n",
        "    if r == 0:\n",
        "        return L / n_months\n",
        "    return L * (r * (1 + r)**n_months) / ((1 + r)**n_months - 1)\n",
        "\n",
        "dfB1[\"installment_expected\"] = dfB1.apply(\n",
        "    lambda row: annuity_payment(row[\"loan_amount\"], row[\"int_rate\"], row[\"term_months\"]),\n",
        "    axis=1\n",
        ")\n",
        "dfB1[\"installment_rel_err\"] = (dfB1[\"installment\"] - dfB1[\"installment_expected\"]) / dfB1[\"installment_expected\"].replace(0, np.nan)\n",
        "dfB1 = dfB1.drop(columns=[\"installment_expected\", \"installment\"], errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfB1[\"loan_to_income\"] = dfB1[\"loan_amount\"] / df[\"annual_income\"].replace(0, np.nan)\n",
        "dfB1 = dfB1.drop(columns=[\"loan_amount\"], errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_title(x):\n",
        "    if pd.isna(x):\n",
        "        return \"unknown\"\n",
        "    x = str(x).lower()\n",
        "    x = re.sub(r\"[^a-z\\s]\", \" \", x)\n",
        "    x = re.sub(r\"\\s+\", \" \", x).strip()\n",
        "    return x if x else \"unknown\"\n",
        "\n",
        "dfB1[\"emp_title_clean\"] = dfB1[\"emp_title\"].apply(clean_title)\n",
        "dfB1[\"emp_title_is_unknown\"] = (dfB1[\"emp_title_clean\"] == \"unknown\").astype(int)\n",
        "dfB1[\"emp_title_len\"] = dfB1[\"emp_title_clean\"].str.len()\n",
        "dfB1 = dfB1.drop(columns=[\"emp_title\"], errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Размерность после feature engineering: (37467, 17)\n",
            "Колонки: ['address_state', 'home_ownership', 'purpose', 'verification_status', 'dti', 'total_acc', 'y', 'issue_month', 'term_months', 'log_income', 'sub_grade_num', 'installment_rel_err', 'loan_to_income', 'emp_title_clean', 'emp_title_is_unknown', 'emp_title_len', 'emp_length_years']\n"
          ]
        }
      ],
      "source": [
        "def parse_emp_length(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    s = str(x).strip().lower()\n",
        "    if s in [\"n/a\", \"na\", \"none\", \"null\", \"\", \"unknown\"]:\n",
        "        return np.nan\n",
        "    if \"<\" in s:\n",
        "        return 0.5\n",
        "    if \"10\" in s:\n",
        "        return 10\n",
        "    m = re.search(r\"(\\d+)\", s)\n",
        "    return float(m.group(1)) if m else np.nan\n",
        "\n",
        "dfB1[\"emp_length_years\"] = dfB1[\"emp_length\"].apply(parse_emp_length)\n",
        "dfB1 = dfB1.drop(columns=[\"emp_length\"], errors='ignore')\n",
        "\n",
        "# Удаляем int_rate (использовали для расчёта)\n",
        "dfB1 = dfB1.drop(columns=[\"int_rate\"], errors='ignore')\n",
        "\n",
        "print(f\"\\nРазмерность после feature engineering: {dfB1.shape}\")\n",
        "print(f\"Колонки: {list(dfB1.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Размеры выборок:\n",
            "Train: (22469, 17), Fraud rate: 0.58%\n",
            "Val: (7018, 17), Fraud rate: 0.58%\n",
            "Test: (7980, 17), Fraud rate: 0.43%\n"
          ]
        }
      ],
      "source": [
        "train_months = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "val_months = [9, 10]\n",
        "test_months = [11, 12]\n",
        "\n",
        "train_df = dfB1[dfB1[\"issue_month\"].isin(train_months)].copy()\n",
        "val_df = dfB1[dfB1[\"issue_month\"].isin(val_months)].copy()\n",
        "test_df = dfB1[dfB1[\"issue_month\"].isin(test_months)].copy()\n",
        "\n",
        "print(f\"\\nРазмеры выборок:\")\n",
        "print(f\"Train: {train_df.shape}, Fraud rate: {train_df['y'].mean()*100:.2f}%\")\n",
        "print(f\"Val: {val_df.shape}, Fraud rate: {val_df['y'].mean()*100:.2f}%\")\n",
        "print(f\"Test: {test_df.shape}, Fraud rate: {test_df['y'].mean()*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "ver_map = {\"Not Verified\": 0, \"Source Verified\": 2, \"Verified\": 1}\n",
        "for d in [train_df, val_df, test_df]:\n",
        "    d[\"verif_ord\"] = d[\"verification_status\"].map(ver_map).fillna(-1).astype(int)\n",
        "    d.drop(\"verification_status\", axis=1, inplace=True, errors='ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def map_home(x):\n",
        "    x = str(x)\n",
        "    if x in [\"RENT\"]: return 2\n",
        "    if x in [\"MORTGAGE\"]: return 3\n",
        "    if x in [\"OWN\"]: return 1\n",
        "    return 0\n",
        "\n",
        "for d in [train_df, val_df, test_df]:\n",
        "    d[\"home_grp\"] = d[\"home_ownership\"].apply(map_home)\n",
        "    d.drop(\"home_ownership\", axis=1, inplace=True, errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "topK = 8\n",
        "top_p = train_df[\"purpose\"].value_counts().head(topK).index\n",
        "\n",
        "for d in [train_df, val_df, test_df]:\n",
        "    d[\"purpose_grp\"] = d[\"purpose\"].where(d[\"purpose\"].isin(top_p), \"OTHER\")\n",
        "    \n",
        "grp2id = {g: i for i, g in enumerate(list(top_p) + [\"OTHER\"], start=1)}\n",
        "\n",
        "for d in [train_df, val_df, test_df]:\n",
        "    d[\"purpose_grp_id\"] = d[\"purpose_grp\"].map(grp2id).fillna(grp2id[\"OTHER\"])\n",
        "    d.drop([\"purpose\", \"purpose_grp\"], axis=1, inplace=True, errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "NORTHEAST = set([\"CT\", \"ME\", \"MA\", \"NH\", \"RI\", \"VT\", \"NJ\", \"NY\", \"PA\"])\n",
        "MIDWEST = set([\"IL\", \"IN\", \"MI\", \"OH\", \"WI\", \"IA\", \"KS\", \"MN\", \"MO\", \"NE\", \"ND\", \"SD\"])\n",
        "SOUTH = set([\"DE\", \"FL\", \"GA\", \"MD\", \"NC\", \"SC\", \"VA\", \"DC\", \"WV\", \"AL\", \"KY\", \"MS\", \"TN\", \"AR\", \"LA\", \"OK\", \"TX\"])\n",
        "WEST = set([\"AZ\", \"CO\", \"ID\", \"MT\", \"NV\", \"NM\", \"UT\", \"WY\", \"AK\", \"CA\", \"HI\", \"OR\", \"WA\"])\n",
        "\n",
        "def state_region(s):\n",
        "    s = str(s)\n",
        "    if s in NORTHEAST: return \"NE\"\n",
        "    if s in MIDWEST: return \"MW\"\n",
        "    if s in SOUTH: return \"S\"\n",
        "    if s in WEST: return \"W\"\n",
        "    return \"UNK\"\n",
        "\n",
        "for d in [train_df, val_df, test_df]:\n",
        "    d[\"state_region\"] = d[\"address_state\"].apply(state_region)\n",
        "    \n",
        "reg_map = {\"NE\": 0, \"MW\": 1, \"S\": 2, \"W\": 3, \"UNK\": 4}\n",
        "for d in [train_df, val_df, test_df]:\n",
        "    d[\"state_region_ord\"] = d[\"state_region\"].map(reg_map).fillna(4).astype(int)\n",
        "    d.drop(columns=[\"state_region\", \"address_state\"], axis=1, inplace=True, errors='ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    min_df=20,\n",
        "    max_features=20000,\n",
        "    ngram_range=(1,2)\n",
        ")\n",
        "\n",
        "X_title_train = tfidf.fit_transform(train_df[\"emp_title_clean\"])\n",
        "X_title_val   = tfidf.transform(val_df[\"emp_title_clean\"])\n",
        "X_title_test  = tfidf.transform(test_df[\"emp_title_clean\"])\n",
        "\n",
        "train_df = train_df.drop(columns=[\"emp_title_clean\"], axis = 1)\n",
        "val_df   = val_df.drop(columns=[\"emp_title_clean\"], axis = 1)\n",
        "test_df  = test_df.drop(columns=[\"emp_title_clean\"], axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['address_state', 'home_ownership', 'purpose', 'verification_status',\n",
              "       'dti', 'total_acc', 'y', 'issue_month', 'term_months', 'log_income',\n",
              "       'sub_grade_num', 'installment_rel_err', 'loan_to_income',\n",
              "       'emp_title_clean', 'emp_title_is_unknown', 'emp_title_len',\n",
              "       'emp_length_years'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfB1.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Series([], dtype: object)\n"
          ]
        }
      ],
      "source": [
        "print(train_df.dtypes[train_df.dtypes == \"object\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train = train_df[\"y\"].values\n",
        "y_val   = val_df[\"y\"].values\n",
        "y_test  = test_df[\"y\"].values\n",
        "\n",
        "\n",
        "X_train = csr_matrix(train_df.drop(columns=[\"y\"]).values)\n",
        "X_val   = csr_matrix(val_df.drop(columns=[\"y\"]).values)\n",
        "X_test  = csr_matrix(test_df.drop(columns=[\"y\"]).values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Финальные размерности:\n",
            "X_train: (22469, 490), y_train: (22469,), fraud: 131\n",
            "X_val: (7018, 490), y_val: (7018,), fraud: 41\n",
            "X_test: (7980, 490), y_test: (7980,), fraud: 34\n"
          ]
        }
      ],
      "source": [
        "y_train = train_df[\"y\"].values\n",
        "y_val = val_df[\"y\"].values\n",
        "y_test = test_df[\"y\"].values\n",
        "\n",
        "\n",
        "train_df = train_df.drop(columns=[\"y\"])\n",
        "val_df = val_df.drop(columns=[\"y\"])\n",
        "test_df = test_df.drop(columns=[\"y\"])\n",
        "\n",
        "\n",
        "for col in train_df.columns:\n",
        "    if train_df[col].dtype in ['float64', 'int64', 'int16']:\n",
        "        median_val = train_df[col].median()\n",
        "        train_df[col] = train_df[col].fillna(median_val)\n",
        "        val_df[col] = val_df[col].fillna(median_val)\n",
        "        test_df[col] = test_df[col].fillna(median_val)\n",
        "\n",
        "\n",
        "X_train_num = csr_matrix(train_df.values)\n",
        "X_val_num = csr_matrix(val_df.values)\n",
        "X_test_num = csr_matrix(test_df.values)\n",
        "\n",
        "X_train = hstack([X_train_num, X_title_train]).tocsr()\n",
        "X_val = hstack([X_val_num, X_title_val]).tocsr()\n",
        "X_test = hstack([X_test_num, X_title_test]).tocsr()\n",
        "\n",
        "print(f\"\\nФинальные размерности:\")\n",
        "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}, fraud: {y_train.sum()}\")\n",
        "print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}, fraud: {y_val.sum()}\")\n",
        "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}, fraud: {y_test.sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    average_precision_score, roc_auc_score, f1_score, \n",
        "    precision_recall_curve, confusion_matrix, precision_score, recall_score\n",
        ")\n",
        "\n",
        "def evaluate_model(model, X, y, dataset_name=\"Test\", threshold=0.01):\n",
        "    \"\"\"Оценка модели с выводом метрик и интерпретацией Precision/Recall\"\"\"\n",
        "    \n",
        "    # Предсказанные вероятности и классы\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        y_pred_proba = model.predict_proba(X)[:, 1]\n",
        "    else:  # для моделей типа SVM\n",
        "        y_pred_proba = model.decision_function(X)\n",
        "    \n",
        "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "    \n",
        "    # Основные метрики\n",
        "    pr_auc = average_precision_score(y, y_pred_proba)\n",
        "    roc_auc = roc_auc_score(y, y_pred_proba)\n",
        "    f1 = f1_score(y, y_pred, zero_division=0)\n",
        "    \n",
        "    # Precision и Recall при текущем threshold\n",
        "    precision = precision_score(y, y_pred, zero_division=0)\n",
        "    recall = recall_score(y, y_pred, zero_division=0)\n",
        "\n",
        "    \n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y, y_pred)\n",
        "    \n",
        "    # Вывод\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"МЕТРИКИ: {dataset_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"PR-AUC (Average Precision): {pr_auc:.4f} ⭐ КЛЮЧЕВАЯ\")\n",
        "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision}  → доля предсказанных fraud, которые реально fraud\")\n",
        "    print(f\"Recall: {recall}  → доля реальных fraud, которые модель поймала\")\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(f\"                 Pred 0   Pred 1\")\n",
        "    print(f\"Actual 0:      {cm[0,0]:6d}   {cm[0,1]:6d}  (Specificity: {cm[0,0]/(cm[0,0]+cm[0,1]):.3f})\")\n",
        "    print(f\"Actual 1:      {cm[1,0]:6d}   {cm[1,1]:6d}  (Recall: {cm[1,1]/(cm[1,0]+cm[1,1]) if (cm[1,0]+cm[1,1])>0 else 0:.3f})\")\n",
        "    \n",
        "    return {\n",
        "        'pr_auc': pr_auc,\n",
        "        'roc_auc': roc_auc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'y_pred_proba': y_pred_proba,\n",
        "        'y_pred': y_pred,\n",
        "        'cm': cm\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Словарь для хранения результатов\n",
        "all_results = {}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# БЕЗ БАЛАНСИРОВКИ (baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Logistic Regression (no balancing) ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR Baseline\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0121 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.7009\n",
            "F1-score: 0.0218\n",
            "Precision: 0.011138613861386138  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 0.5294117647058824  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:        6348     1598  (Specificity: 0.799)\n",
            "Actual 1:          16       18  (Recall: 0.529)\n"
          ]
        }
      ],
      "source": [
        "# 10.1.1 Логистическая регрессия\n",
        "print(\"\\n--- Logistic Regression (no balancing) ---\")\n",
        "lr_baseline = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
        "lr_baseline.fit(X_train, y_train)\n",
        "res_lr_base = evaluate_model(lr_baseline, X_test, y_test, \"LR Baseline\")\n",
        "res_lr_base['y_true'] = y_test\n",
        "all_results['LR_Baseline'] = res_lr_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Decision Tree (no balancing) ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: DT Baseline\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0054 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.4948\n",
            "F1-score: 0.0109\n",
            "Precision: 0.005623242736644799  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 0.17647058823529413  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:        6885     1061  (Specificity: 0.866)\n",
            "Actual 1:          28        6  (Recall: 0.176)\n"
          ]
        }
      ],
      "source": [
        "# 10.1.2 Decision Tree\n",
        "print(\"\\n--- Decision Tree (no balancing) ---\")\n",
        "dt_baseline = DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_leaf=50)\n",
        "dt_baseline.fit(X_train, y_train)\n",
        "res_dt_base = evaluate_model(dt_baseline, X_test, y_test, \"DT Baseline\")\n",
        "res_dt_base['y_true'] = y_test\n",
        "all_results['DT_Baseline'] = res_dt_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- HistGradientBoosting (no balancing) ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: HGB Baseline\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0062 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.6222\n",
            "F1-score: 0.0145\n",
            "Precision: 0.007598784194528876  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 0.14705882352941177  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:        7293      653  (Specificity: 0.918)\n",
            "Actual 1:          29        5  (Recall: 0.147)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 10.1.3 HistGradientBoosting\n",
        "print(\"\\n--- HistGradientBoosting (no balancing) ---\")\n",
        "hgb_baseline = HistGradientBoostingClassifier(random_state=42, max_iter=100, early_stopping=True, \n",
        "                                               validation_fraction=0.1, n_iter_no_change=10)\n",
        "hgb_baseline.fit(X_train.toarray(), y_train)\n",
        "res_hgb_base = evaluate_model(hgb_baseline, X_test.toarray(), y_test, \"HGB Baseline\")\n",
        "res_hgb_base['y_true'] = y_test\n",
        "all_results['HGB_Baseline'] = res_hgb_base\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "балансировка + oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер после ROS: (23008, 490), распределение: [22338   670]\n"
          ]
        }
      ],
      "source": [
        "ros = RandomOverSampler(sampling_strategy=0.03, random_state=42)  # fraud = 3% от датасета\n",
        "X_train_ros, y_train_ros = ros.fit_resample(X_train.toarray(), y_train)\n",
        "\n",
        "print(f\"Размер после ROS: {X_train_ros.shape}, распределение: {np.bincount(y_train_ros)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Logistic Regression (балансировка + oversampling) ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR Balanced + Oversampling (TEST)\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0064 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5661\n",
            "F1-score: 0.0089\n",
            "Precision: 0.0044601862783680965  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         357     7589  (Specificity: 0.045)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Logistic Regression (балансировка + oversampling) ---\")\n",
        "\n",
        "lr_balanced = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight={0: 1, 1: 20}\n",
        ")\n",
        "\n",
        "# ✅ обучение — oversampled train\n",
        "lr_balanced.fit(X_train_ros, y_train_ros)\n",
        "\n",
        "\n",
        "# ✅ оценка — ЧИСТЫЙ TEST\n",
        "res_lr_bal = evaluate_model(\n",
        "    lr_balanced,\n",
        "    X_test,\n",
        "    y_test,\n",
        "    \"LR Balanced + Oversampling (TEST)\"\n",
        ")\n",
        "\n",
        "all_results['LR_Balanced + Oversampling'] = res_lr_bal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "OVERSAMPLING ratio = 0.05\n",
            "======================================================================\n",
            "Train size after ROS: (23454, 490)\n",
            "Class distribution: [22338  1116]\n",
            "\n",
            "--- LR_ros0.05_w5 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.05_w5\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0077 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5971\n",
            "F1-score: 0.0088\n",
            "Precision: 0.004442702208284333  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         327     7619  (Specificity: 0.041)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "--- LR_ros0.05_w10 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.05_w10\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0068 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5728\n",
            "F1-score: 0.0088\n",
            "Precision: 0.004435746901500326  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         315     7631  (Specificity: 0.040)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "--- LR_ros0.05_w15 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.05_w15\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0069 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5662\n",
            "F1-score: 0.0088\n",
            "Precision: 0.004419027813880946  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         286     7660  (Specificity: 0.036)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "--- LR_ros0.05_w20 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.05_w20\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0063 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5571\n",
            "F1-score: 0.0090\n",
            "Precision: 0.004503907802357928  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         431     7515  (Specificity: 0.054)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "--- LR_ros0.05_w30 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.05_w30\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0063 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5637\n",
            "F1-score: 0.0088\n",
            "Precision: 0.004419027813880946  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         286     7660  (Specificity: 0.036)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "======================================================================\n",
            "OVERSAMPLING ratio = 0.1\n",
            "======================================================================\n",
            "Train size after ROS: (24571, 490)\n",
            "Class distribution: [22338  2233]\n",
            "\n",
            "--- LR_ros0.1_w5 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.1_w5\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0079 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5866\n",
            "F1-score: 0.0087\n",
            "Precision: 0.004370741740583622  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         201     7745  (Specificity: 0.025)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "--- LR_ros0.1_w10 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.1_w10\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0067 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5637\n",
            "F1-score: 0.0090\n",
            "Precision: 0.004515871961747908  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         451     7495  (Specificity: 0.057)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "--- LR_ros0.1_w15 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.1_w15\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0069 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5743\n",
            "F1-score: 0.0088\n",
            "Precision: 0.004436325678496869  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         316     7630  (Specificity: 0.040)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "--- LR_ros0.1_w20 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.1_w20\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0068 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5601\n",
            "F1-score: 0.0090\n",
            "Precision: 0.004524886877828055  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         466     7480  (Specificity: 0.059)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "--- LR_ros0.1_w30 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.1_w30\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0065 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5713\n",
            "F1-score: 0.0087\n",
            "Precision: 0.004383137811009411  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         223     7723  (Specificity: 0.028)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "======================================================================\n",
            "OVERSAMPLING ratio = 0.2\n",
            "======================================================================\n",
            "Train size after ROS: (26805, 490)\n",
            "Class distribution: [22338  4467]\n",
            "\n",
            "--- LR_ros0.2_w5 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.2_w5\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0069 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5645\n",
            "F1-score: 0.0090\n",
            "Precision: 0.004536962903656259  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         486     7460  (Specificity: 0.061)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "--- LR_ros0.2_w10 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.2_w10\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0072 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5803\n",
            "F1-score: 0.0086\n",
            "Precision: 0.004341164453524004  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         148     7798  (Specificity: 0.019)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "--- LR_ros0.2_w15 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.2_w15\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0066 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5659\n",
            "F1-score: 0.0090\n",
            "Precision: 0.004527296937416778  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         470     7476  (Specificity: 0.059)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "--- LR_ros0.2_w20 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.2_w20\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0067 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5706\n",
            "F1-score: 0.0089\n",
            "Precision: 0.004494976203067161  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         416     7530  (Specificity: 0.052)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "--- LR_ros0.2_w30 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.2_w30\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0073 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5818\n",
            "F1-score: 0.0086\n",
            "Precision: 0.004342273307790549  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         150     7796  (Specificity: 0.019)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "======================================================================\n",
            "OVERSAMPLING ratio = 0.3\n",
            "======================================================================\n",
            "Train size after ROS: (29039, 490)\n",
            "Class distribution: [22338  6701]\n",
            "\n",
            "--- LR_ros0.3_w5 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.3_w5\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0069 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5708\n",
            "F1-score: 0.0089\n",
            "Precision: 0.00444560669456067  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         332     7614  (Specificity: 0.042)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "--- LR_ros0.3_w10 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.3_w10\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0069 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5706\n",
            "F1-score: 0.0088\n",
            "Precision: 0.004412719013627515  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         275     7671  (Specificity: 0.035)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "--- LR_ros0.3_w15 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.3_w15\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0065 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5694\n",
            "F1-score: 0.0089\n",
            "Precision: 0.004481349677079215  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         393     7553  (Specificity: 0.049)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "--- LR_ros0.3_w20 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.3_w20\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0068 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5732\n",
            "F1-score: 0.0088\n",
            "Precision: 0.0044334333029078105  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         311     7635  (Specificity: 0.039)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n",
            "\n",
            "--- LR_ros0.3_w30 ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR_ros0.3_w30\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0064 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5602\n",
            "F1-score: 0.0091\n",
            "Precision: 0.0045772751750134625  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         552     7394  (Specificity: 0.069)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "pos_weights = [5, 10, 15, 20, 30]\n",
        "sampling_strategies = [0.05, 0.1, 0.2, 0.3]\n",
        "\n",
        "for ratio in sampling_strategies:\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"OVERSAMPLING ratio = {ratio}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    ros = RandomOverSampler(\n",
        "        random_state=42,\n",
        "        sampling_strategy=ratio\n",
        "    )\n",
        "\n",
        "    X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(f\"Train size after ROS: {X_train_ros.shape}\")\n",
        "    print(f\"Class distribution: {np.bincount(y_train_ros)}\")\n",
        "\n",
        "    for w in pos_weights:\n",
        "        model_name = f\"LR_ros{ratio}_w{w}\"\n",
        "\n",
        "        print(f\"\\n--- {model_name} ---\")\n",
        "\n",
        "        lr = LogisticRegression(\n",
        "            max_iter=1000,\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "            class_weight={0: 1, 1: w}\n",
        "        )\n",
        "\n",
        "        lr.fit(X_train_ros, y_train_ros)\n",
        "\n",
        "        res = evaluate_model(\n",
        "            lr,\n",
        "            X_test,        # ❗ test, не train\n",
        "            y_test,\n",
        "            dataset_name=model_name\n",
        "        )\n",
        "\n",
        "        res[\"oversampling_ratio\"] = ratio\n",
        "        res[\"pos_weight\"] = w\n",
        "\n",
        "        all_results[model_name] = res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Decision Tree (балансировка + oversampling) ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: DT Balanced\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0061 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5586\n",
            "F1-score: 0.0105\n",
            "Precision: 0.005323505323505323  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 0.38235294117647056  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:        5517     2429  (Specificity: 0.694)\n",
            "Actual 1:          21       13  (Recall: 0.382)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Decision Tree (балансировка + oversampling) ---\")\n",
        "weights = {0:1, 1:15}\n",
        "dt_balanced = DecisionTreeClassifier(\n",
        "    random_state=42,\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=50,\n",
        "    class_weight=weights\n",
        ")\n",
        "dt_balanced.fit(X_train_ros, y_train_ros)\n",
        "res_dt_bal = evaluate_model(dt_balanced, X_test, y_test, \"DT Balanced\")\n",
        "res_dt_bal['y_true'] = y_test\n",
        "all_results['DT_Balanced + Oversampling'] = res_dt_bal"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "HistGradientBoosting class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- HistGradientBoosting (балансировка) ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: HGB + ROS\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0078 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.6538\n",
            "F1-score: 0.0085\n",
            "Precision: 0.004260651629072682  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:           0     7946  (Specificity: 0.000)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- HistGradientBoosting (балансировка) ---\")\n",
        "hgb_balanced = HistGradientBoostingClassifier(\n",
        "    max_iter=200,\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=20,\n",
        "    random_state=42,\n",
        "    class_weight={0:1, 1:50}  \n",
        ")\n",
        "hgb_balanced.fit(X_train.toarray(), y_train)\n",
        "res_hgb_balanced = evaluate_model(hgb_balanced, X_test.toarray(), y_test, \"HGB + ROS\")\n",
        "res_hgb_balanced['y_true'] = y_test\n",
        "all_results['HGB_balanced'] = res_hgb_balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- HistGradientBoosting (Random Oversampling) ---\n",
            "\n",
            "============================================================\n",
            "МЕТРИКИ: HGB + ROS\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0058 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5497\n",
            "F1-score: 0.0098\n",
            "Precision: 0.0049504950495049506  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 0.47058823529411764  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:        4730     3216  (Specificity: 0.595)\n",
            "Actual 1:          18       16  (Recall: 0.471)\n"
          ]
        }
      ],
      "source": [
        "# 10.3.3 HistGradientBoosting\n",
        "print(\"\\n--- HistGradientBoosting (Random Oversampling) ---\")\n",
        "hgb_ros = HistGradientBoostingClassifier(random_state=42, max_iter=100)\n",
        "hgb_ros.fit(X_train_ros.toarray(), y_train_ros)\n",
        "res_hgb_ros = evaluate_model(hgb_ros, X_test.toarray(), y_test, \"HGB + ROS\")\n",
        "res_hgb_ros['y_true'] = y_test\n",
        "all_results['HGB_ROS'] = res_hgb_ros"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "smote = SMOTE(sampling_strategy=0.03, random_state=42, k_neighbors=3)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train.toarray(), y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "МЕТРИКИ: LR Balanced + SMOTE\n",
            "============================================================\n",
            "PR-AUC (Average Precision): 0.0073 ⭐ КЛЮЧЕВАЯ\n",
            "ROC-AUC: 0.5842\n",
            "F1-score: 0.0088\n",
            "Precision: 0.004418453541260559  → доля предсказанных fraud, которые реально fraud\n",
            "Recall: 1.0  → доля реальных fraud, которые модель поймала\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred 0   Pred 1\n",
            "Actual 0:         285     7661  (Specificity: 0.036)\n",
            "Actual 1:           0       34  (Recall: 1.000)\n"
          ]
        }
      ],
      "source": [
        "lr_balanced_smote = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1, class_weight={0:1, 1:15})\n",
        "lr_balanced_smote.fit(X_train_smote, y_train_smote)\n",
        "res_lr_bal_smote = evaluate_model(lr_balanced_smote, X_test, y_test, \"LR Balanced + SMOTE\")\n",
        "res_lr_bal_smote['y_true'] = y_test\n",
        "all_results['LR_Balanced + SMOTE'] = res_lr_bal_smote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                     Model   PR-AUC  ROC-AUC       F1   Recall  Precision:\n",
            "               LR_Baseline 0.012066 0.700937 0.021818 0.529412    0.011139\n",
            "              LR_ros0.1_w5 0.007939 0.586614 0.008703 1.000000    0.004371\n",
            "              HGB_balanced 0.007826 0.653751 0.008485 1.000000    0.004261\n",
            "             LR_ros0.05_w5 0.007693 0.597100 0.008846 1.000000    0.004443\n",
            "       LR_Balanced + SMOTE 0.007317 0.584234 0.008798 1.000000    0.004418\n",
            "             LR_ros0.2_w30 0.007281 0.581795 0.008647 1.000000    0.004342\n",
            "             LR_ros0.2_w10 0.007174 0.580281 0.008645 1.000000    0.004341\n",
            "              LR_ros0.2_w5 0.006935 0.564550 0.009033 1.000000    0.004537\n",
            "             LR_ros0.3_w10 0.006934 0.570568 0.008787 1.000000    0.004413\n",
            "              LR_ros0.3_w5 0.006910 0.570813 0.008852 1.000000    0.004446\n",
            "            LR_ros0.05_w15 0.006900 0.566230 0.008799 1.000000    0.004419\n",
            "             LR_ros0.1_w15 0.006890 0.574344 0.008833 1.000000    0.004436\n",
            "             LR_ros0.3_w20 0.006817 0.573230 0.008828 1.000000    0.004433\n",
            "            LR_ros0.05_w10 0.006788 0.572763 0.008832 1.000000    0.004436\n",
            "             LR_ros0.1_w20 0.006754 0.560145 0.009009 1.000000    0.004525\n",
            "             LR_ros0.2_w20 0.006729 0.570561 0.008950 1.000000    0.004495\n",
            "             LR_ros0.1_w10 0.006718 0.563746 0.008991 1.000000    0.004516\n",
            "             LR_ros0.2_w15 0.006586 0.565860 0.009014 1.000000    0.004527\n",
            "             LR_ros0.3_w15 0.006516 0.569406 0.008923 1.000000    0.004481\n",
            "             LR_ros0.1_w30 0.006482 0.571253 0.008728 1.000000    0.004383\n",
            "             LR_ros0.3_w30 0.006417 0.560249 0.009113 1.000000    0.004577\n",
            "LR_Balanced + Oversampling 0.006361 0.566064 0.008881 1.000000    0.004460\n",
            "            LR_ros0.05_w30 0.006327 0.563728 0.008799 1.000000    0.004419\n",
            "            LR_ros0.05_w20 0.006317 0.557143 0.008967 1.000000    0.004504\n",
            "              HGB_Baseline 0.006181 0.622172 0.014451 0.147059    0.007599\n",
            "DT_Balanced + Oversampling 0.006131 0.558553 0.010501 0.382353    0.005324\n",
            "                   HGB_ROS 0.005783 0.549711 0.009798 0.470588    0.004950\n",
            "               DT_Baseline 0.005365 0.494831 0.010899 0.176471    0.005623\n"
          ]
        }
      ],
      "source": [
        "results_df = pd.DataFrame([\n",
        "    {\n",
        "        'Model': name,\n",
        "        'PR-AUC': res['pr_auc'],\n",
        "        'ROC-AUC': res['roc_auc'],\n",
        "        'F1': res['f1'],\n",
        "        'Recall': res['recall'],\n",
        "        'Precision:': res['precision']\n",
        "        \n",
        "    }\n",
        "    for name, res in all_results.items()\n",
        "        if name != 'LR_VAL'\n",
        "])\n",
        "\n",
        "results_df = results_df.sort_values('PR-AUC', ascending=False)\n",
        "print(\"\\n\" + results_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ros = RandomOverSampler(sampling_strategy=0.03, random_state=42)  # fraud = 3% от датасета\n",
        "X_train_ros, y_train_ros = ros.fit_resample(X_train.toarray(), y_train)\n",
        "\n",
        "print(\"\\n--- Logistic Regression (балансировка + oversampling) ---\")\n",
        "lr_balanced = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1, class_weight={0:1, 1:100})\n",
        "lr_balanced.fit(X_train_ros, y_train_ros)\n",
        "res_lr_bal = evaluate_model(lr_balanced, X_train_ros, y_train_ros, \"LR Balanced + Oversampling\")\n",
        "res_lr_bal['y_true'] = y_test\n",
        "all_results['LR_Balanced + Oversampling'] = res_lr_bal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_val_proba = lr_baseline.predict_proba(X_val)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_val, y_val_proba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best threshold: 0.013674828836965747\n",
            "Precision: 0.016270337922403004\n",
            "Recall: 0.3170731707317073\n",
            "F1: 0.030952380023837895\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "\n",
        "best_idx = np.argmax(f1_scores)\n",
        "best_threshold = thresholds[best_idx]\n",
        "\n",
        "print(\"Best threshold:\", best_threshold)\n",
        "print(\"Precision:\", precision[best_idx])\n",
        "print(\"Recall:\", recall[best_idx])\n",
        "print(\"F1:\", f1_scores[best_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Нет threshold с таким precision\n"
          ]
        }
      ],
      "source": [
        "target_precision = 0.2\n",
        "\n",
        "valid_idxs = np.where(precision[:-1] >= target_precision)[0]\n",
        "\n",
        "if len(valid_idxs) > 0:\n",
        "    idx = valid_idxs[np.argmax(recall[valid_idxs])]\n",
        "    print(\"Threshold:\", thresholds[idx])\n",
        "    print(\"Precision:\", precision[idx])\n",
        "    print(\"Recall:\", recall[idx])\n",
        "else:\n",
        "    print(\"Нет threshold с таким precision\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (Anaconda)",
      "language": "python",
      "name": "anaconda"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
